{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Logistic Regression Model - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the last lesson you were given a broad overview of logistic regression. This included an introduction to two separate packages for creating logistic regression models. In this lab, you'll be investigating fitting logistic regressions with `statsmodels`. For your first foray into logistic regression, you are going to attempt to build a model that classifies whether an individual survived the [Titanic](https://www.kaggle.com/c/titanic/data) shipwreck or not (yes, it's a bit morbid).\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "* Implement logistic regression with `statsmodels` \n",
    "* Interpret the statistical results associated with model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "Import the data stored in the file `'titanic.csv'` and print the first five rows of the DataFrame to check its contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define independent and target variables\n",
    "\n",
    "Your target variable is in the column `'Survived'`. A `0` indicates that the passenger didn't survive the shipwreck. Print the total number of people who didn't survive the shipwreck. How many people survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qd/fg3r712s5yndq5jp2rks347m0000gp/T/ipykernel_18505/2436534865.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Total number of people who survived/didn't survive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "# Total number of people who survived/didn't survive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider the columns specified in `relevant_columns` when building your model. The next step is to create dummy variables from categorical variables. Remember to drop the first level for each categorical column and make sure all the values are of type `float`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      891 non-null    int64  \n",
      " 1   Age         714 non-null    float64\n",
      " 2   SibSp       891 non-null    int64  \n",
      " 3   Fare        891 non-null    float64\n",
      " 4   Survived    891 non-null    int64  \n",
      " 5   Sex_male    891 non-null    float64\n",
      " 6   Embarked_Q  891 non-null    float64\n",
      " 7   Embarked_S  891 non-null    float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 55.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "relevant_columns = ['Pclass', 'Age', 'SibSp', 'Fare', 'Sex', 'Embarked', 'Survived']\n",
    "dummy_dataframe = pd.get_dummies(df[relevant_columns], drop_first=True, dtype=float)\n",
    "\n",
    "dummy_dataframe.shape\n",
    "dummy_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice above that the DataFrame contains missing values? To keep things simple, simply delete all rows with missing values. \n",
    "\n",
    "> NOTE: You can use the [`.dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 714 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      714 non-null    int64  \n",
      " 1   Age         714 non-null    float64\n",
      " 2   SibSp       714 non-null    int64  \n",
      " 3   Fare        714 non-null    float64\n",
      " 4   Survived    714 non-null    int64  \n",
      " 5   Sex_male    714 non-null    float64\n",
      " 6   Embarked_Q  714 non-null    float64\n",
      " 7   Embarked_S  714 non-null    float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 50.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Drop missing rows\n",
    "dummy_dataframe = dummy_dataframe.dropna()\n",
    "dummy_dataframe.shape\n",
    "dummy_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, assign the independent variables to `X` and the target variable to `y`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "y = dummy_dataframe['Survived']\n",
    "X = dummy_dataframe.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now with everything in place, you can build a logistic regression model using `statsmodels` (make sure you create an intercept term as we showed in the previous lesson).  \n",
    "\n",
    "> Warning: Did you receive an error of the form \"LinAlgError: Singular matrix\"? This means that `statsmodels` was unable to fit the model due to certain linear algebra computational problems. Specifically, the matrix was not invertible due to not being full rank. In other words, there was a lot of redundant, superfluous data. Try removing some features from the model and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.443267\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Build a logistic regression model using statsmodels\n",
    "\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sma\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "X = sma.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "titanic_model = sma.Logit(y, X)\n",
    "\n",
    "# Get results of the fit\n",
    "result = titanic_model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "Generate the summary table for your model. Then, comment on the p-values associated with the various features you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Survived</td>     <th>  No. Observations:  </th>  <td>   714</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   706</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 23 Sep 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.3437</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>08:21:29</td>     <th>  Log-Likelihood:    </th> <td> -316.49</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -482.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.103e-67</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>    5.6503</td> <td>    0.633</td> <td>    8.921</td> <td> 0.000</td> <td>    4.409</td> <td>    6.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>     <td>   -1.2118</td> <td>    0.163</td> <td>   -7.433</td> <td> 0.000</td> <td>   -1.531</td> <td>   -0.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>        <td>   -0.0431</td> <td>    0.008</td> <td>   -5.250</td> <td> 0.000</td> <td>   -0.059</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>      <td>   -0.3806</td> <td>    0.125</td> <td>   -3.048</td> <td> 0.002</td> <td>   -0.625</td> <td>   -0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>       <td>    0.0012</td> <td>    0.002</td> <td>    0.474</td> <td> 0.636</td> <td>   -0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_male</th>   <td>   -2.6236</td> <td>    0.217</td> <td>  -12.081</td> <td> 0.000</td> <td>   -3.049</td> <td>   -2.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th> <td>   -0.8260</td> <td>    0.598</td> <td>   -1.381</td> <td> 0.167</td> <td>   -1.999</td> <td>    0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_S</th> <td>   -0.4130</td> <td>    0.269</td> <td>   -1.533</td> <td> 0.125</td> <td>   -0.941</td> <td>    0.115</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     Survived     & \\textbf{  No. Observations:  } &      714    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      706    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        7    \\\\\n",
       "\\textbf{Date:}            & Mon, 23 Sep 2024 & \\textbf{  Pseudo R-squ.:     } &   0.3437    \\\\\n",
       "\\textbf{Time:}            &     08:21:29     & \\textbf{  Log-Likelihood:    } &   -316.49   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -482.26   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 1.103e-67   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                     & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}       &       5.6503  &        0.633     &     8.921  &         0.000        &        4.409    &        6.892     \\\\\n",
       "\\textbf{Pclass}      &      -1.2118  &        0.163     &    -7.433  &         0.000        &       -1.531    &       -0.892     \\\\\n",
       "\\textbf{Age}         &      -0.0431  &        0.008     &    -5.250  &         0.000        &       -0.059    &       -0.027     \\\\\n",
       "\\textbf{SibSp}       &      -0.3806  &        0.125     &    -3.048  &         0.002        &       -0.625    &       -0.136     \\\\\n",
       "\\textbf{Fare}        &       0.0012  &        0.002     &     0.474  &         0.636        &       -0.004    &        0.006     \\\\\n",
       "\\textbf{Sex\\_male}   &      -2.6236  &        0.217     &   -12.081  &         0.000        &       -3.049    &       -2.198     \\\\\n",
       "\\textbf{Embarked\\_Q} &      -0.8260  &        0.598     &    -1.381  &         0.167        &       -1.999    &        0.347     \\\\\n",
       "\\textbf{Embarked\\_S} &      -0.4130  &        0.269     &    -1.533  &         0.125        &       -0.941    &        0.115     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  714\n",
       "Model:                          Logit   Df Residuals:                      706\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Mon, 23 Sep 2024   Pseudo R-squ.:                  0.3437\n",
       "Time:                        08:21:29   Log-Likelihood:                -316.49\n",
       "converged:                       True   LL-Null:                       -482.26\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.103e-67\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.6503      0.633      8.921      0.000       4.409       6.892\n",
       "Pclass        -1.2118      0.163     -7.433      0.000      -1.531      -0.892\n",
       "Age           -0.0431      0.008     -5.250      0.000      -0.059      -0.027\n",
       "SibSp         -0.3806      0.125     -3.048      0.002      -0.625      -0.136\n",
       "Fare           0.0012      0.002      0.474      0.636      -0.004       0.006\n",
       "Sex_male      -2.6236      0.217    -12.081      0.000      -3.049      -2.198\n",
       "Embarked_Q    -0.8260      0.598     -1.381      0.167      -1.999       0.347\n",
       "Embarked_S    -0.4130      0.269     -1.533      0.125      -0.941       0.115\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary table\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comments here\n",
    "# Age, Class, Number of Siblings and sex(male) are all statitically signficant with the Lower Class, Higher age, less number of siblings and if you're male\n",
    "# leading to an increase chance you will not survive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "Create a new model, this time only using those features you determined were influential based on your analysis of the results above. How does this model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Well done! In this lab, you practiced using `statsmodels` to build a logistic regression model. You then interpreted the results, building upon your previous stats knowledge, similar to linear regression. Continue on to take a look at building logistic regression models in Scikit-learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
